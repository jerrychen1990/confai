[common_config]
# 项目名称
project_name : topic_cls
# owner:
owner : confai
#是否要做模型训练
is_train : True
#是否要做模型测试
is_test : True
#是否要做模型保存
is_save : False
#如果is_save=True,控制模型保存的参数。format表示模型文件的格式可选:pth(默认)
save_args : {"nn_model_types": ["torch"]}
#如果is_test=True,控制测试阶段需要对那些数据集做测评，可选：train/dev/test
#输入数据必须包含true_predict才能写入eval_phase_list
eval_phase_list : ['train', 'eval', 'test']
#如果is_test=True,控制测试阶段需要对那些数据集结果做输出，可选：train/dev/test
output_phase_list : ['eval', 'test']
desc : "topic classify with chinese_roberta_L-12_H-768"

#输出的experiment文件是否覆盖旧的experiment文件。默认False
#is_overwrite_experiment=True：experiment目录为{experiment_dir}/{project_name}/{model_name}
#is_overwrite_experiment=False：experiment目录为{experiment_dir}/{project_name}/{model_name}-{current_time}
is_overwrite_experiment : True
#设置随机种子，让实验可以复现。不设置则每次实验随机生成一个seed
seed : 10

# 模型类型 所有类型详见config_ai.ALL_MODELS
model_cls : CLSTokenClsModel
# 模型名称；最终模型保存地址: {experiment_dir}/{project_name}/{model_name}
model_name : roberta_cls


[tokenizer_config]
tokenizer_path : uer/chinese_roberta_L-12_H-768

[nn_model_config]
# 预训练模型名称(huggingface中model的全名)
pretrained_model_name :uer/chinese_roberta_L-12_H-768

#具体任务特定模型相关的配置
[task_config]
# 模型可接受的最大序列长度
max_len : 128
multi_label: False
label_path: /data/nlp/data/text_cls/watson-topic-cls/labels.txt

[data_config]
#训练数据文件，jsonl格式，要有label字段
train_data_path : /data/nlp/data/text_cls/watson-topic-cls/train.jsonl
eval_data_path : /data/nlp/data/text_cls/watson-topic-cls/eval.jsonl
test_data_path : /data/nlp/data/text_cls/watson-topic-cls/test.jsonl



[train_config]
# 整个训练过程的epoch数量
num_train_epochs : 10
batch_size : 32
eval_batch_size : 32
evaluation_strategy: steps
logging_steps : 1000
save_strategy: no


#测试阶段配置, 详见wiki/test.md
[test_config]
# 每次给模型测试的batch大小
batch_size : 64


[callback_config]
eval_save : {"eval_steps":1000, "metric_jpath":"$.micro.f1", "tgt_metric": 1.}


